{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SELF ATTENTION IMPLEMENTATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask=None):\n",
    "    key_dim = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    scaled_scores = tf.matmul(query, key, transpose_b=True) / np.sqrt(key_dim)\n",
    "    if mask is not None:\n",
    "        scaled_scores = tf.where(mask==0, -np.inf, scaled_scores)\n",
    "    \n",
    "    softmax = tf.keras.layers.Softmax()\n",
    "    weights = softmax(scaled_scores)\n",
    "    return tf.matmul(weights, value), weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queries:  [[0.64462257 0.29182289 0.59699105 0.62766912]\n",
      " [0.87747214 0.50352764 0.3700742  0.6824152 ]\n",
      " [0.95345309 0.59851879 0.54799055 0.45626173]]\n"
     ]
    }
   ],
   "source": [
    "seq_len = 3\n",
    "embedding_dim = 4\n",
    "queries = np.random.rand(seq_len, embedding_dim)\n",
    "keys = np.random.rand(seq_len, embedding_dim)\n",
    "values = np.random.rand(seq_len, embedding_dim)\n",
    "\n",
    "print(\"Queries: \", queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:  tf.Tensor(\n",
      "[[0.39585012 0.51225656 0.4863063  0.42944267]\n",
      " [0.40387934 0.5078269  0.48785013 0.4239037 ]\n",
      " [0.40933886 0.5035388  0.48784375 0.42252594]], shape=(3, 4), dtype=float32)\n",
      "Weights:  tf.Tensor(\n",
      "[[0.40565223 0.273214   0.32113376]\n",
      " [0.40638384 0.25693667 0.33667943]\n",
      " [0.40383312 0.2503343  0.34583256]], shape=(3, 3), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-15 02:35:33.999954: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-15 02:35:34.034712: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-15 02:35:34.035155: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-15 02:35:34.036740: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-15 02:35:34.036969: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-15 02:35:34.037149: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-15 02:35:34.102949: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-15 02:35:34.103179: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-15 02:35:34.103364: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-15 02:35:34.103510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4273 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "output, attention_weights = scaled_dot_product_attention(queries, keys, values)\n",
    "print(\"Output: \", output)\n",
    "print(\"Weights: \", attention_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MULTI-HEAD SELF ATTENTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of each head: 4\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "seq_len = 3\n",
    "embedding_dim = 12\n",
    "num_heads = 3\n",
    "head_dim = embedding_dim // num_heads\n",
    "print(f\"Dimension of each head: {head_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  (1, 3, 12) \n",
      "\n",
      "Input: \n",
      " [[[0.9 0.2 0.2 0.6 0.1 1.  0.1 0.1 0.7 1.  0.  1. ]\n",
      "  [0.6 0.8 0.9 1.  0.5 1.  0.2 1.  0.9 0.8 0.2 0.7]\n",
      "  [0.3 0.9 0.3 0.5 0.2 0.8 0.3 0.6 0.6 0.4 0.9 0.7]]]\n"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(batch_size, seq_len, embedding_dim).round(1)\n",
    "print(\"Input shape: \", x.shape, \"\\n\")\n",
    "print(\"Input: \\n\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "wq0 = np.random.rand(embedding_dim, head_dim).round(1)\n",
    "wk0 = np.random.rand(embedding_dim, head_dim).round(1)\n",
    "wv0 = np.random.rand(embedding_dim, head_dim).round(1)\n",
    "\n",
    "wq1 = np.random.rand(embedding_dim, head_dim).round(1)\n",
    "wk1 = np.random.rand(embedding_dim, head_dim).round(1)\n",
    "wv1 = np.random.rand(embedding_dim, head_dim).round(1)\n",
    "\n",
    "wq2 = np.random.rand(embedding_dim, head_dim).round(1)\n",
    "wk2 = np.random.rand(embedding_dim, head_dim).round(1)\n",
    "wv2 = np.random.rand(embedding_dim, head_dim).round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The three sets of query weights (one for each head): \n",
      "wq0: \n",
      " [[0.5 0.8 0.4 0.7]\n",
      " [0.4 0.3 0.4 0.6]\n",
      " [0.5 0.2 0.3 0.6]\n",
      " [0.9 0.9 0.5 0.2]\n",
      " [0.5 0.4 0.5 0.6]\n",
      " [0.3 1.  0.7 0.2]\n",
      " [0.5 0.5 0.4 0.9]\n",
      " [0.3 0.3 0.1 0. ]\n",
      " [0.9 0.6 0.8 0.6]\n",
      " [0.9 0.1 0.2 0.1]\n",
      " [0.9 0.1 1.  0.5]\n",
      " [0.6 0.1 0.8 0.4]]\n",
      "wq1: \n",
      " [[0.5 0.3 0.2 1. ]\n",
      " [0.  0.7 0.9 0.2]\n",
      " [0.7 0.4 0.9 0.8]\n",
      " [0.3 0.2 0.7 0.4]\n",
      " [0.2 0.9 0.3 0. ]\n",
      " [0.7 0.1 0.2 0.1]\n",
      " [0.  0.2 0.4 0.4]\n",
      " [0.1 0.5 0.6 0.8]\n",
      " [0.5 0.  0.3 0.3]\n",
      " [0.2 1.  0.4 0.3]\n",
      " [0.3 0.8 0.9 0.3]\n",
      " [0.2 0.7 0.3 0.8]]\n",
      "wq2: \n",
      " [[0.6 0.1 0.1 0.1]\n",
      " [0.  0.  0.5 0.9]\n",
      " [0.5 0.5 0.4 0.2]\n",
      " [0.2 0.9 0.4 0.5]\n",
      " [0.  0.8 0.4 0.2]\n",
      " [0.9 1.  0.9 0.4]\n",
      " [0.1 0.2 0.6 0.6]\n",
      " [0.2 0.5 0.4 1. ]\n",
      " [0.5 1.  0.5 0.1]\n",
      " [0.4 0.1 0.3 0.3]\n",
      " [0.5 0.9 0.9 0.4]\n",
      " [0.1 0.8 0.3 0.8]]\n"
     ]
    }
   ],
   "source": [
    "print(\"The three sets of query weights (one for each head): \")\n",
    "print(\"wq0: \\n\", wq0)\n",
    "print(\"wq1: \\n\", wq1)\n",
    "print(\"wq2: \\n\", wq2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "q0 = np.dot(x, wq0)\n",
    "q1 = np.dot(x, wq1)\n",
    "q2 = np.dot(x, wq2)\n",
    "\n",
    "k0 = np.dot(x, wk0)\n",
    "k1 = np.dot(x, wk1)\n",
    "k2 = np.dot(x, wk2)\n",
    "\n",
    "v0 = np.dot(x, wv0)\n",
    "v1 = np.dot(x, wv1)\n",
    "v2 = np.dot(x, wv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q, K, and V for first head:\n",
      "\n",
      "q0 (1, 3, 4):\n",
      " [[[3.73 3.1  3.16 2.26]\n",
      "  [5.05 4.11 4.1  3.32]\n",
      "  [3.91 2.79 3.68 2.71]]] \n",
      "\n",
      "k0 (1, 3, 4):\n",
      " [[[2.93 3.02 2.98 2.86]\n",
      "  [4.47 3.71 4.93 3.84]\n",
      "  [3.41 2.98 3.52 3.41]]] \n",
      "\n",
      "v0 (1, 3, 4):\n",
      " [[[2.6  3.09 3.23 4.2 ]\n",
      "  [4.42 4.03 4.87 5.54]\n",
      "  [3.4  2.57 3.04 4.11]]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Q, K, and V for first head:\\n\")\n",
    "\n",
    "print(f\"q0 {q0.shape}:\\n\", q0, \"\\n\")\n",
    "print(f\"k0 {k0.shape}:\\n\", k0, \"\\n\")\n",
    "print(f\"v0 {v0.shape}:\\n\", v0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from the first attention head:  tf.Tensor(\n",
      "[[[4.416455  4.0254145 4.8641167 5.535385 ]\n",
      "  [4.419542  4.029374  4.8692064 5.5393796]\n",
      "  [4.4178185 4.0271072 4.86631   5.5371084]]], shape=(1, 3, 4), dtype=float32)\n",
      "Weights from the first attention head:  tf.Tensor(\n",
      "[[[2.9361187e-04 9.9675459e-01 2.9517696e-03]\n",
      "  [1.7891492e-05 9.9956471e-01 4.1743321e-04]\n",
      "  [1.3759677e-04 9.9796957e-01 1.8927344e-03]]], shape=(1, 3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "output_0, attention_weights_0 = scaled_dot_product_attention(q0, k0, v0)\n",
    "print(\"Output from the first attention head: \", output_0)\n",
    "print(\"Weights from the first attention head: \", attention_weights_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from the second attention head:  tf.Tensor(\n",
      "[[[4.2350297 3.9552813 5.328367  3.783058 ]\n",
      "  [4.2396684 3.959685  5.3391848 3.789499 ]\n",
      "  [4.2377996 3.9579113 5.334864  3.7869403]]], shape=(1, 3, 4), dtype=float32)\n",
      "Output from the third attention head:  tf.Tensor(\n",
      "[[[4.2667036 3.626774  4.30675   5.2757072]\n",
      "  [4.2698565 3.6298625 4.3098617 5.279814 ]\n",
      "  [4.2691364 3.629193  4.30919   5.2788815]]], shape=(1, 3, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "output_1, _ = scaled_dot_product_attention(q1, k1, v1)\n",
    "output_2, _ = scaled_dot_product_attention(q2, k2, v2)\n",
    "\n",
    "print(\"Output from the second attention head: \", output_1)\n",
    "print(\"Output from the third attention head: \", output_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query weights for the first head:  [[0.5 0.8 0.4 0.7]\n",
      " [0.4 0.3 0.4 0.6]\n",
      " [0.5 0.2 0.3 0.6]\n",
      " [0.9 0.9 0.5 0.2]\n",
      " [0.5 0.4 0.5 0.6]\n",
      " [0.3 1.  0.7 0.2]\n",
      " [0.5 0.5 0.4 0.9]\n",
      " [0.3 0.3 0.1 0. ]\n",
      " [0.9 0.6 0.8 0.6]\n",
      " [0.9 0.1 0.2 0.1]\n",
      " [0.9 0.1 1.  0.5]\n",
      " [0.6 0.1 0.8 0.4]]\n",
      "Query weights for the second head:  [[0.5 0.3 0.2 1. ]\n",
      " [0.  0.7 0.9 0.2]\n",
      " [0.7 0.4 0.9 0.8]\n",
      " [0.3 0.2 0.7 0.4]\n",
      " [0.2 0.9 0.3 0. ]\n",
      " [0.7 0.1 0.2 0.1]\n",
      " [0.  0.2 0.4 0.4]\n",
      " [0.1 0.5 0.6 0.8]\n",
      " [0.5 0.  0.3 0.3]\n",
      " [0.2 1.  0.4 0.3]\n",
      " [0.3 0.8 0.9 0.3]\n",
      " [0.2 0.7 0.3 0.8]]\n",
      "Query weights for the third head:  [[0.6 0.1 0.1 0.1]\n",
      " [0.  0.  0.5 0.9]\n",
      " [0.5 0.5 0.4 0.2]\n",
      " [0.2 0.9 0.4 0.5]\n",
      " [0.  0.8 0.4 0.2]\n",
      " [0.9 1.  0.9 0.4]\n",
      " [0.1 0.2 0.6 0.6]\n",
      " [0.2 0.5 0.4 1. ]\n",
      " [0.5 1.  0.5 0.1]\n",
      " [0.4 0.1 0.3 0.3]\n",
      " [0.5 0.9 0.9 0.4]\n",
      " [0.1 0.8 0.3 0.8]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Query weights for the first head: \", wq0)\n",
    "print(\"Query weights for the second head: \", wq1)\n",
    "print(\"Query weights for the third head: \", wq2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single query weight matrix: (12, 12): \n",
      " [[0.5 0.8 0.4 0.7 0.5 0.3 0.2 1.  0.6 0.1 0.1 0.1]\n",
      " [0.4 0.3 0.4 0.6 0.  0.7 0.9 0.2 0.  0.  0.5 0.9]\n",
      " [0.5 0.2 0.3 0.6 0.7 0.4 0.9 0.8 0.5 0.5 0.4 0.2]\n",
      " [0.9 0.9 0.5 0.2 0.3 0.2 0.7 0.4 0.2 0.9 0.4 0.5]\n",
      " [0.5 0.4 0.5 0.6 0.2 0.9 0.3 0.  0.  0.8 0.4 0.2]\n",
      " [0.3 1.  0.7 0.2 0.7 0.1 0.2 0.1 0.9 1.  0.9 0.4]\n",
      " [0.5 0.5 0.4 0.9 0.  0.2 0.4 0.4 0.1 0.2 0.6 0.6]\n",
      " [0.3 0.3 0.1 0.  0.1 0.5 0.6 0.8 0.2 0.5 0.4 1. ]\n",
      " [0.9 0.6 0.8 0.6 0.5 0.  0.3 0.3 0.5 1.  0.5 0.1]\n",
      " [0.9 0.1 0.2 0.1 0.2 1.  0.4 0.3 0.4 0.1 0.3 0.3]\n",
      " [0.9 0.1 1.  0.5 0.3 0.8 0.9 0.3 0.5 0.9 0.9 0.4]\n",
      " [0.6 0.1 0.8 0.4 0.2 0.7 0.3 0.8 0.1 0.8 0.3 0.8]]\n"
     ]
    }
   ],
   "source": [
    "wq = np.concatenate([wq0, wq1, wq2], axis=1)\n",
    "print(f\"Single query weight matrix: {wq.shape}: \\n\", wq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single key weight matrix: (12, 12): \n",
      " [[0.1 1.  0.8 0.4 0.  0.1 0.6 0.4 0.3 0.6 0.4 0.4]\n",
      " [0.4 0.3 0.9 0.6 0.9 0.1 0.5 0.7 0.  0.9 0.7 0.6]\n",
      " [0.7 0.8 1.  0.1 0.6 0.8 0.5 0.6 0.6 0.6 0.7 0.6]\n",
      " [0.3 0.3 0.4 0.8 0.1 0.6 0.5 0.2 0.7 0.9 0.3 0.1]\n",
      " [0.  0.1 0.7 0.  0.2 0.2 0.6 0.8 0.7 0.4 1.  0.3]\n",
      " [0.8 0.1 0.4 0.7 0.  0.6 0.5 0.1 0.4 1.  0.2 0.2]\n",
      " [0.1 0.5 0.4 0.3 0.1 0.8 0.7 0.5 0.7 0.7 0.7 0.8]\n",
      " [0.7 0.1 0.6 0.5 0.4 0.5 0.1 1.  0.2 0.2 0.3 0.1]\n",
      " [0.8 0.5 0.1 0.  0.9 0.9 0.7 0.6 0.  0.  0.9 0.7]\n",
      " [0.8 0.5 0.9 0.4 0.8 0.7 0.2 0.2 0.5 0.5 0.4 0.8]\n",
      " [0.7 0.8 0.6 0.8 0.2 0.3 0.5 0.9 0.7 0.1 0.  0.1]\n",
      " [0.2 0.7 0.1 0.7 0.5 0.4 0.7 0.1 0.  0.3 0.7 0.9]]\n",
      "Single value weight matrix: (12, 12): \n",
      " [[0.4 0.7 0.8 1.  0.2 0.4 1.  0.3 0.6 0.1 0.8 0.2]\n",
      " [0.7 0.1 0.1 0.2 0.4 0.7 0.9 0.3 0.5 0.  0.3 0.8]\n",
      " [0.4 0.8 0.6 1.  0.1 0.3 1.  0.  0.9 0.7 0.7 0.5]\n",
      " [0.9 0.1 0.8 0.8 0.6 0.9 0.7 0.8 0.4 0.2 0.1 0.9]\n",
      " [0.6 1.  0.6 0.3 1.  0.1 0.9 0.2 0.1 1.  0.5 0.3]\n",
      " [0.  0.5 0.7 1.  0.2 0.2 0.2 0.3 0.1 0.6 0.6 0.8]\n",
      " [0.4 0.8 0.6 0.7 0.4 0.4 0.8 0.4 0.5 0.9 0.5 0.3]\n",
      " [0.5 0.4 0.9 0.2 0.9 0.8 0.5 0.2 0.7 0.  0.2 1. ]\n",
      " [0.9 0.  0.4 0.8 0.6 0.  0.7 0.9 0.5 0.4 0.8 0.2]\n",
      " [0.4 0.8 0.6 0.6 0.1 0.5 0.  0.6 0.2 1.  0.6 0.2]\n",
      " [0.7 0.1 0.2 0.9 0.9 0.9 0.3 0.2 0.9 0.1 0.1 0.6]\n",
      " [0.3 0.7 0.1 0.3 0.9 0.4 0.6 0.8 0.8 0.4 0.7 1. ]]\n"
     ]
    }
   ],
   "source": [
    "wk = np.concatenate([wk0, wk1, wk2], axis=1)\n",
    "wv = np.concatenate([wv0, wv1, wv2], axis=1)\n",
    "\n",
    "print(f\"Single key weight matrix: {wk.shape}: \\n\", wk)\n",
    "print(f\"Single value weight matrix: {wv.shape}: \\n\", wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_s = np.dot(x, wq)\n",
    "k_s = np.dot(x, wk)\n",
    "v_s = np.dot(x, wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query vectors using a single weight matrix (1, 3, 12):\n",
      " [[[3.73 3.1  3.16 2.26 2.25 2.57 2.2  2.87 2.54 3.48 2.5  2.36]\n",
      "  [5.05 4.11 4.1  3.32 2.94 3.84 4.36 3.99 3.07 5.07 3.92 4.05]\n",
      "  [3.91 2.79 3.68 2.71 1.96 3.17 3.55 2.73 2.28 3.96 3.46 3.39]]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Query vectors using a single weight matrix {q_s.shape}:\\n\", q_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined queries: (1, 3, 12)\n",
      " [[[3.73 3.1  3.16 2.26 2.25 2.57 2.2  2.87 2.54 3.48 2.5  2.36]\n",
      "  [5.05 4.11 4.1  3.32 2.94 3.84 4.36 3.99 3.07 5.07 3.92 4.05]\n",
      "  [3.91 2.79 3.68 2.71 1.96 3.17 3.55 2.73 2.28 3.96 3.46 3.39]]]\n",
      "Reshaped into separate heads: (1, 3, 3, 4)\n",
      " tf.Tensor(\n",
      "[[[[3.73 3.1  3.16 2.26]\n",
      "   [2.25 2.57 2.2  2.87]\n",
      "   [2.54 3.48 2.5  2.36]]\n",
      "\n",
      "  [[5.05 4.11 4.1  3.32]\n",
      "   [2.94 3.84 4.36 3.99]\n",
      "   [3.07 5.07 3.92 4.05]]\n",
      "\n",
      "  [[3.91 2.79 3.68 2.71]\n",
      "   [1.96 3.17 3.55 2.73]\n",
      "   [2.28 3.96 3.46 3.39]]]], shape=(1, 3, 3, 4), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "q_s_reshaped = tf.reshape(q_s, (batch_size, seq_len, num_heads, head_dim))\n",
    "print(f'Combined queries: {q_s.shape}\\n', q_s)\n",
    "print(f\"Reshaped into separate heads: {q_s_reshaped.shape}\\n\", q_s_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queries transposed into \"seprate\" heads (1, 3, 3, 4): \n",
      " [[[[3.73 3.1  3.16 2.26]\n",
      "   [5.05 4.11 4.1  3.32]\n",
      "   [3.91 2.79 3.68 2.71]]\n",
      "\n",
      "  [[2.25 2.57 2.2  2.87]\n",
      "   [2.94 3.84 4.36 3.99]\n",
      "   [1.96 3.17 3.55 2.73]]\n",
      "\n",
      "  [[2.54 3.48 2.5  2.36]\n",
      "   [3.07 5.07 3.92 4.05]\n",
      "   [2.28 3.96 3.46 3.39]]]]\n"
     ]
    }
   ],
   "source": [
    "q_s_transposed = tf.transpose(q_s_reshaped, perm=[0, 2, 1, 3]).numpy()\n",
    "print(f\"Queries transposed into \\\"seprate\\\" heads {q_s_transposed.shape}: \\n\", q_s_transposed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The separate per-head query matrices from before: \n",
      "[[[3.73 3.1  3.16 2.26]\n",
      "  [5.05 4.11 4.1  3.32]\n",
      "  [3.91 2.79 3.68 2.71]]] \n",
      "\n",
      "[[[2.25 2.57 2.2  2.87]\n",
      "  [2.94 3.84 4.36 3.99]\n",
      "  [1.96 3.17 3.55 2.73]]] \n",
      "\n",
      "[[[2.54 3.48 2.5  2.36]\n",
      "  [3.07 5.07 3.92 4.05]\n",
      "  [2.28 3.96 3.46 3.39]]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"The separate per-head query matrices from before: \")\n",
    "print(q0, \"\\n\")\n",
    "print(q1, \"\\n\")\n",
    "print(q2, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys for all heads in a single matrix (1, 3, 12): \n",
      " [[[[2.93 3.02 2.98 2.86]\n",
      "   [4.47 3.71 4.93 3.84]\n",
      "   [3.41 2.98 3.52 3.41]]\n",
      "\n",
      "  [[2.36 3.11 3.07 1.79]\n",
      "   [3.72 4.53 4.13 4.09]\n",
      "   [2.74 3.09 3.26 3.34]]\n",
      "\n",
      "  [[1.87 3.31 2.95 3.17]\n",
      "   [3.05 4.69 4.49 3.89]\n",
      "   [2.24 3.33 3.05 2.87]]]] \n",
      "\n",
      "Values for all heads in a single matrix (1, 3, 12): \n",
      " [[[[2.6  3.09 3.23 4.2 ]\n",
      "   [4.42 4.03 4.87 5.54]\n",
      "   [3.4  2.57 3.04 4.11]]\n",
      "\n",
      "  [[2.49 2.33 3.21 3.22]\n",
      "   [4.24 3.96 5.34 3.79]\n",
      "   [3.61 3.36 3.75 2.8 ]]\n",
      "\n",
      "  [[2.64 2.82 3.56 3.28]\n",
      "   [4.27 3.63 4.31 5.28]\n",
      "   [3.52 2.3  2.92 4.21]]]]\n"
     ]
    }
   ],
   "source": [
    "k_s_transposed = tf.transpose(tf.reshape(k_s, (batch_size, -1, num_heads, head_dim)), perm=[0, 2, 1, 3]).numpy()\n",
    "v_s_transposed = tf.transpose(tf.reshape(v_s, (batch_size, -1, num_heads, head_dim)), perm=[0, 2, 1, 3]).numpy()\n",
    "\n",
    "\n",
    "print(f\"Keys for all heads in a single matrix {k_s.shape}: \\n\", k_s_transposed, \"\\n\")\n",
    "print(f\"Values for all heads in a single matrix {v_s.shape}: \\n\", v_s_transposed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self Attention output: \n",
      " tf.Tensor(\n",
      "[[[[4.416455  4.0254145 4.8641167 5.535385 ]\n",
      "   [4.419542  4.029374  4.8692064 5.5393796]\n",
      "   [4.4178185 4.0271072 4.86631   5.5371084]]\n",
      "\n",
      "  [[4.2350297 3.9552813 5.328367  3.783058 ]\n",
      "   [4.2396684 3.959685  5.3391848 3.789499 ]\n",
      "   [4.2377996 3.9579113 5.334864  3.7869403]]\n",
      "\n",
      "  [[4.2667036 3.626774  4.30675   5.2757072]\n",
      "   [4.2698565 3.6298625 4.3098617 5.279814 ]\n",
      "   [4.2691364 3.629193  4.30919   5.2788815]]]], shape=(1, 3, 3, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "all_heads_output, all_attention_weights = scaled_dot_product_attention(q_s_transposed, k_s_transposed, v_s_transposed)\n",
    "print(\"Self Attention output: \\n\", all_heads_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final output from using single query, key, value matrices:\n",
      " tf.Tensor(\n",
      "[[[4.416455  4.0254145 4.8641167 5.535385  4.2350297 3.9552813 5.328367\n",
      "   3.783058  4.2667036 3.626774  4.30675   5.2757072]\n",
      "  [4.419542  4.029374  4.8692064 5.5393796 4.2396684 3.959685  5.3391848\n",
      "   3.789499  4.2698565 3.6298625 4.3098617 5.279814 ]\n",
      "  [4.4178185 4.0271072 4.86631   5.5371084 4.2377996 3.9579113 5.334864\n",
      "   3.7869403 4.2691364 3.629193  4.30919   5.2788815]]], shape=(1, 3, 12), dtype=float32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "combined_out_b = tf.reshape(tf.transpose(all_heads_output, perm=[0, 2, 1, 3]), (batch_size, seq_len, embedding_dim))\n",
    "combined_out_b.shape\n",
    "print(\"Final output from using single query, key, value matrices:\\n\", \n",
    "      combined_out_b, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads  \n",
    "\n",
    "        self.d_heads = self.d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(self.d_model)\n",
    "        self.wk = tf.keras.layers.Dense(self.d_model)\n",
    "        self.wv = tf.keras.layers.Dense(self.d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(self.d_model)\n",
    "\n",
    "    def split_heads(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        split_inputs = tf.reshape(x, (batch_size, -1, self.num_heads, self.d_heads))\n",
    "        return tf.transpose(split_inputs, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def merge_heads(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        merged_inputs = tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "        return tf.reshape(merged_inputs, (batch_size, -1, self.d_model))\n",
    "    \n",
    "    def call(self, q, k, v, mask):\n",
    "        qs = self.wq(q)\n",
    "        ks = self.wk(k)\n",
    "        vs = self.wv(v)\n",
    "\n",
    "        qs = self.split_heads(qs)\n",
    "        ks = self.split_heads(ks)\n",
    "        vs = self.split_heads(vs)\n",
    "\n",
    "        output, attention_weights = scaled_dot_product_attention(qs, ks, vs, mask)\n",
    "        output = self.merge_heads(output)\n",
    "\n",
    "        return self.dense(output), attention_weights\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MHSA output: (1, 3, 12)\n",
      " tf.Tensor(\n",
      "[[[ 0.7243886   0.38871232 -0.3713587   0.08256346 -1.4231125\n",
      "    0.29189828  1.0245624   0.82307565  0.13167898 -0.6788002\n",
      "    0.10989675  0.430043  ]\n",
      "  [ 0.7192505   0.39557058 -0.38501424  0.0737307  -1.4221615\n",
      "    0.30300948  1.0384811   0.8434766   0.14299577 -0.68396413\n",
      "    0.09957641  0.44049442]\n",
      "  [ 0.7430325   0.36705524 -0.3678645   0.04611637 -1.3885686\n",
      "    0.3037917   1.0396196   0.84250486  0.12326129 -0.6774776\n",
      "    0.11347139  0.4388766 ]]], shape=(1, 3, 12), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "mhsa = MultiHeadSelfAttention(12, 3)\n",
    "\n",
    "output, attention_weights = mhsa(x, x, x, mask=None)\n",
    "print(f\"MHSA output: {output.shape}\\n\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward_network(d_model, hidden_dim):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(hidden_dim, activation='relu'),\n",
    "        tf.keras.layers.Dense(d_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, hidden_dim, dropout_rate=0.1):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        self.mhsa = MultiHeadSelfAttention(d_model, num_heads)\n",
    "        self.ffn = feed_forward_network(d_model, hidden_dim)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "        mhsa_output, attention_weights = self.mhsa(x, x, x, mask)\n",
    "        mhsa_output = self.dropout1(mhsa_output, training=training)\n",
    "        mhsa_output = self.layernorm1(x + mhsa_output)\n",
    "\n",
    "        ffn_output = self.ffn(mhsa_output)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        output = self.layernorm2(mhsa_output + ffn_output)\n",
    "\n",
    "        return output, attention_weights\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder block output: (1, 3, 12)\n",
      " tf.Tensor(\n",
      "[[[-0.5077105  -0.10255369  0.01637811  1.1511724   1.5025967\n",
      "    1.3684464  -0.996069   -1.1237533  -1.2633322   1.1438186\n",
      "   -1.0470654  -0.1419278 ]\n",
      "  [-1.126212    0.05545544  1.2249769   1.0827426   1.3357245\n",
      "    0.9501109  -1.1947788  -0.5905926  -1.6235039   0.69403183\n",
      "   -0.67660743 -0.13134727]\n",
      "  [-1.0390782   0.08097543  1.4713725   0.7167139   1.1496494\n",
      "    1.4686049  -1.0459328  -0.63145953 -1.6693597  -0.1600641\n",
      "    0.2727188  -0.61414015]]], shape=(1, 3, 12), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "encoder_block = EncoderBlock(12, 3, 48)\n",
    "\n",
    "block_output, _ = encoder_block(x, training=True, mask=None)\n",
    "print(f\"Encoder block output: {block_output.shape}\\n\", block_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size:  10000\n",
      "Embedding size:  100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.305548, -0.325598, -0.134716, -0.078735, -0.660545,  0.076211,\n",
       "       -0.735487,  0.124533, -0.294402,  0.459688,  0.030137,  0.174041,\n",
       "       -0.224223,  0.486189, -0.504649, -0.459699,  0.315747,  0.477885,\n",
       "        0.091398,  0.427867,  0.016524, -0.076833, -0.899727,  0.493158,\n",
       "       -0.022309, -0.422785, -0.154148,  0.204981,  0.379834,  0.070588,\n",
       "        0.196073, -0.368222,  0.473406,  0.007409,  0.004303, -0.007823,\n",
       "       -0.19103 , -0.202509,  0.109878, -0.224521, -0.35741 , -0.611633,\n",
       "        0.329958, -0.212956, -0.497499, -0.393839, -0.130101, -0.216903,\n",
       "       -0.105595, -0.076007, -0.483942, -0.139704, -0.161647,  0.136985,\n",
       "        0.415363, -0.360143,  0.038601, -0.078804, -0.030421,  0.324129,\n",
       "        0.223378, -0.523636, -0.048317, -0.032248, -0.117367,  0.470519,\n",
       "        0.225816, -0.222065, -0.225007, -0.165904, -0.334389, -0.20157 ,\n",
       "        0.572352, -0.268794,  0.301929, -0.005563,  0.387491,  0.261031,\n",
       "       -0.11613 ,  0.074982, -0.008433,  0.259987, -0.099893, -0.268875,\n",
       "       -0.054047, -0.534776, -0.111101, -0.051742,  0.214114,  0.04293 ,\n",
       "        0.039873, -0.453112,  0.087382, -0.333201, -0.034079, -0.833045,\n",
       "        0.155232, -1.132393, -0.294766,  0.327572], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bpemb import BPEmb\n",
    "\n",
    "bpemb_en = BPEmb(model_file=\"dl/en.wiki.bpe.vs10000.model\", emb_file=\"dl/en.wiki.bpe.vs10000.d100.w2v.txt\")\n",
    "\n",
    "bpemb_vocab_size, bpemb_embedding_size = bpemb_en.vectors.shape\n",
    "print(\"Vocabulary size: \", bpemb_vocab_size)\n",
    "print(\"Embedding size: \", bpemb_embedding_size)\n",
    "\n",
    "bpemb_en.vectors[bpemb_en.words.index('car')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁this', '▁is', '▁a', '▁test', '▁sentence', '.']\n",
      "[ 215   80    4 1417 8018 9935]\n"
     ]
    }
   ],
   "source": [
    "sample_sentence = \"This is a test sentence.\"\n",
    "tokens = bpemb_en.encode(sample_sentence)\n",
    "print(tokens)\n",
    "\n",
    "#to vectorize the tokens, we can use\n",
    "token_seq = np.array(bpemb_en.encode_ids(sample_sentence))\n",
    "print(token_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings for:  This is a test sentence.\n",
      "tf.Tensor(\n",
      "[[ 0.04325885  0.0153905   0.0084916   0.01765759 -0.04393685 -0.02584207\n",
      "   0.00741035  0.00529586  0.04138687 -0.00108188 -0.01214737  0.04320996]\n",
      " [ 0.02488294 -0.03764825 -0.00791397 -0.01074302  0.01572687  0.04023686\n",
      "   0.00198406 -0.01887797  0.02190575 -0.03720016 -0.01135868 -0.03820722]\n",
      " [-0.01751604 -0.02321208 -0.03165638 -0.00679427  0.02897458  0.03856293\n",
      "  -0.04542214  0.00415289 -0.01453358 -0.03599155 -0.01077665  0.03040539]\n",
      " [ 0.00730227 -0.04022131  0.00711285  0.0370374   0.00355294  0.04821488\n",
      "   0.00257929 -0.00746938 -0.00266268 -0.02074823  0.03379487 -0.01936979]\n",
      " [-0.01358979 -0.01693592  0.01879406  0.04581114 -0.0020567   0.03432843\n",
      "   0.03771757  0.00042767 -0.00427796 -0.04699645 -0.02356578  0.0465809 ]\n",
      " [ 0.01933826 -0.01900394  0.03576306  0.04497225  0.04902435  0.0424873\n",
      "   0.02289401 -0.02709107  0.04170777 -0.0101452  -0.04986476  0.0079672 ]], shape=(6, 12), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "token_embed = tf.keras.layers.Embedding(bpemb_vocab_size, embedding_dim)\n",
    "token_embeddings = token_embed(token_seq)\n",
    "\n",
    "print(\"Embeddings for: \", sample_sentence)\n",
    "print(token_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ADDING POSITIONAL INFORMATION TO WORD EMBEDDINGS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3 4 5], shape=(6,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "max_seq_len = 256\n",
    "pos_embed = tf.keras.layers.Embedding(max_seq_len, embedding_dim)\n",
    "\n",
    "#ids for each position of the token sequence\n",
    "pos_idx = tf.range(len(token_seq))\n",
    "print(pos_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position embeddings for the input sequence:  tf.Tensor(\n",
      "[[-0.03398951 -0.04240065 -0.0395308   0.02028023  0.03782424 -0.00674021\n",
      "   0.04054494 -0.04820068 -0.04032767 -0.01148112  0.02223236 -0.02714597]\n",
      " [ 0.01064237  0.01306362 -0.032097    0.04778328 -0.02553469 -0.00102216\n",
      "  -0.00287461  0.04004383 -0.04058469  0.03487198 -0.02273406  0.00374869]\n",
      " [ 0.0334586   0.03806755 -0.0353977   0.03569827  0.01905346 -0.01626587\n",
      "  -0.02591124  0.02015717  0.03362096 -0.03954991 -0.03974589 -0.0472868 ]\n",
      " [ 0.03146205  0.00368471  0.00429564  0.01074628 -0.04690666 -0.02014521\n",
      "   0.03664566 -0.01319785  0.02634666 -0.01850809 -0.04733215 -0.02704452]\n",
      " [ 0.03837686  0.01326886 -0.01699028  0.04684622  0.01942888  0.04434233\n",
      "   0.01320937  0.02857763 -0.03618866 -0.04637827 -0.02180573 -0.04060348]\n",
      " [-0.02767768 -0.0091346   0.03583739  0.0139837  -0.00317991  0.00021335\n",
      "   0.01069367  0.04481942 -0.0356519  -0.04820929 -0.01352438 -0.02875545]], shape=(6, 12), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "position_embeddings = pos_embed(pos_idx)\n",
    "print(\"Position embeddings for the input sequence: \", position_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial input embeddings:  tf.Tensor(\n",
      "[[ 0.00926934 -0.02701014 -0.0310392   0.03793782 -0.00611261 -0.03258228\n",
      "   0.04795529 -0.04290482  0.0010592  -0.012563    0.01008499  0.01606399]\n",
      " [ 0.03552531 -0.02458463 -0.04001097  0.03704026 -0.00980782  0.0392147\n",
      "  -0.00089055  0.02116586 -0.01867894 -0.00232818 -0.03409274 -0.03445853]\n",
      " [ 0.01594256  0.01485547 -0.06705408  0.02890399  0.04802804  0.02229706\n",
      "  -0.07133337  0.02431006  0.01908738 -0.07554146 -0.05052254 -0.01688141]\n",
      " [ 0.03876432 -0.0365366   0.01140849  0.04778368 -0.04335373  0.02806967\n",
      "   0.03922496 -0.02066723  0.02368398 -0.03925632 -0.01353728 -0.04641432]\n",
      " [ 0.02478707 -0.00366706  0.00180378  0.09265736  0.01737218  0.07867076\n",
      "   0.05092694  0.0290053  -0.04046662 -0.09337471 -0.04537151  0.00597742]\n",
      " [-0.00833942 -0.02813854  0.07160044  0.05895595  0.04584444  0.04270064\n",
      "   0.03358768  0.01772834  0.00605587 -0.05835449 -0.06338914 -0.02078825]], shape=(6, 12), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "input = token_embeddings + position_embeddings\n",
    "print(\"Initial input embeddings: \", input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_blocks, d_model, num_heads, hidden_dim, vocab_size, max_seq_len, dropout_rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "        self.token_embed = tf.keras.layers.Embedding(vocab_size, self.d_model)\n",
    "        self.pos_embed = tf.keras.layers.Embedding(max_seq_len, self.d_model)\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "        self.blocks = [EncoderBlock(d_model, num_heads, hidden_dim, dropout_rate)\n",
    "        for _ in range(num_blocks)]\n",
    "\n",
    "    def call(self, input, training, mask):\n",
    "        token_embeds = self.token_embed(input)\n",
    "        num_pos = input.shape[0] * self.max_seq_len\n",
    "        pos_idx = np.resize(np.arange(self.max_seq_len), num_pos)\n",
    "        pos_idx = np.reshape(pos_idx, input.shape)\n",
    "        pos_embeds = self.pos_embed(pos_idx)\n",
    "\n",
    "        x = self.dropout(token_embeds + pos_embeds, training=training)\n",
    "\n",
    "        for block in self.blocks:\n",
    "            x, weights = block(x, training, mask)\n",
    "\n",
    "        return x, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['▁where', '▁can', '▁i', '▁find', '▁a', '▁p', 'iz', 'zer', 'ia', '?'],\n",
       " ['▁mass', '▁hy', 'ster', 'ia', '▁over', '▁l', 'ister', 'ia', '.'],\n",
       " ['▁i', '▁a', 'in', \"'\", 't', '▁no', '▁circle', '▁back', '▁girl', '.']]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_batch = [\n",
    "    \"Where can I find a pizzeria?\",\n",
    "    \"Mass hysteria over listeria.\",\n",
    "    \"I ain't no circle back girl.\"\n",
    "]\n",
    "\n",
    "bpemb_en.encode(input_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized inputs:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[571, 280, 386, 1934, 4, 24, 248, 4339, 177, 9967],\n",
       " [1535, 1354, 1238, 177, 380, 43, 871, 177, 9935],\n",
       " [386, 4, 6, 9937, 9915, 467, 5410, 810, 3692, 9935]]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seqs = bpemb_en.encode_ids(input_batch)\n",
    "print(\"Vectorized inputs:\")\n",
    "input_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input to the encoder:\n",
      "(3, 10)\n",
      "[[ 571  280  386 1934    4   24  248 4339  177 9967]\n",
      " [1535 1354 1238  177  380   43  871  177 9935    0]\n",
      " [ 386    4    6 9937 9915  467 5410  810 3692 9935]]\n"
     ]
    }
   ],
   "source": [
    "padded_input_seqs = tf.keras.preprocessing.sequence.pad_sequences(input_seqs, padding=\"post\")\n",
    "print(\"Input to the encoder:\")\n",
    "print(padded_input_seqs.shape)\n",
    "print(padded_input_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "[[ 571  280  386 1934    4   24  248 4339  177 9967]\n",
      " [1535 1354 1238  177  380   43  871  177 9935    0]\n",
      " [ 386    4    6 9937 9915  467 5410  810 3692 9935]] \n",
      "\n",
      "Encoder mask:\n",
      "tf.Tensor(\n",
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]], shape=(3, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "enc_mask = tf.cast(tf.math.not_equal(padded_input_seqs, 0), tf.float32)\n",
    "print(\"Input:\")\n",
    "print(padded_input_seqs, '\\n')\n",
    "print(\"Encoder mask:\")\n",
    "print(enc_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1, 1, 10), dtype=float32, numpy=\n",
       "array([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., 1., 1., 1., 1., 1., 1., 0.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_mask = enc_mask[:, tf.newaxis, tf.newaxis, :]\n",
    "enc_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_encoder_blocks = 6\n",
    "d_model = 12\n",
    "num_heads = 3\n",
    "ffn_hidden_dim = 48\n",
    "vocab_size = bpemb_vocab_size\n",
    "max_input_seq_len = padded_input_seqs.shape[1]\n",
    "\n",
    "encoder = Encoder(num_encoder_blocks, d_model, num_heads, ffn_hidden_dim, vocab_size, max_input_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output (3, 10, 12): \n",
      "tf.Tensor(\n",
      "[[[-3.26760858e-03 -1.20480120e+00  6.22624159e-01  6.83924079e-01\n",
      "    1.05118525e+00 -1.91665018e+00 -2.97412992e-01  1.14766693e+00\n",
      "   -1.25742567e+00 -5.53451419e-01  1.11791718e+00  6.09691143e-01]\n",
      "  [-7.21426010e-01 -6.35106802e-01 -2.51689777e-02  1.04358411e+00\n",
      "    5.00864089e-01 -2.01896977e+00 -8.15164268e-01  1.48712456e+00\n",
      "   -8.20116043e-01  7.16940105e-01  1.26338995e+00  2.40489393e-02]\n",
      "  [-4.43812877e-01 -1.25330758e+00 -1.26191020e-01 -6.65307283e-01\n",
      "    1.72754753e+00 -6.60814643e-01 -1.64348960e-01  7.81626463e-01\n",
      "   -8.78134370e-01 -7.89120555e-01  2.03146505e+00  4.40398306e-01]\n",
      "  [-2.89231271e-01 -1.33801448e+00 -2.58275300e-01  6.04404867e-01\n",
      "    1.04361665e+00 -1.29179239e+00 -6.83233500e-01  1.09148645e+00\n",
      "   -1.16659510e+00 -2.44480252e-01  1.83680677e+00  6.95307612e-01]\n",
      "  [ 6.11717813e-02 -1.12667572e+00 -1.24916658e-01  8.64175737e-01\n",
      "    1.07200050e+00 -1.57508302e+00 -7.35716105e-01  1.02798140e+00\n",
      "   -5.52397251e-01 -6.37603402e-01  1.98898530e+00 -2.61922687e-01]\n",
      "  [-1.43459177e+00 -5.01850605e-01  7.62836814e-01  1.41827190e+00\n",
      "   -2.95515478e-01 -1.80424464e+00 -2.49966979e-01  1.54587340e+00\n",
      "   -5.84593654e-01  6.56684875e-01  6.96432829e-01 -2.09336787e-01]\n",
      "  [-1.04130363e+00 -1.06460369e+00  3.05200964e-02  8.33387494e-01\n",
      "    1.93045855e-01 -8.20133805e-01 -2.47731805e-04  1.50302660e+00\n",
      "   -1.34071743e+00  3.60641092e-01  1.95457566e+00 -6.08190536e-01]\n",
      "  [-3.89716268e-01 -1.10625935e+00 -4.00024235e-01  7.51398206e-01\n",
      "   -2.38784671e-01 -1.24162543e+00 -6.16553128e-01  1.59309173e+00\n",
      "   -9.06097412e-01 -1.40957721e-02  2.07891297e+00  4.89753574e-01]\n",
      "  [-1.56127453e+00 -1.02404132e-01  5.16126394e-01  9.41773891e-01\n",
      "    1.36246085e+00 -1.91452181e+00 -5.54613352e-01  1.40882373e+00\n",
      "   -1.75463021e-01  5.88359833e-01 -5.72919250e-02 -4.51976150e-01]\n",
      "  [-6.97801888e-01 -9.84107614e-01  7.47170746e-02  7.49361217e-01\n",
      "    7.42585480e-01 -2.35938692e+00  2.43292347e-01  1.15141821e+00\n",
      "   -5.17221928e-01  3.52028757e-02  1.48303401e+00  7.89072812e-02]]\n",
      "\n",
      " [[-6.95096970e-01 -1.29330218e+00  1.30575454e+00 -6.89556152e-02\n",
      "    1.63659722e-01 -6.87621117e-01  1.56385437e-01  1.83990300e+00\n",
      "   -1.89652467e+00  6.66592941e-02  6.20905459e-01  4.88233447e-01]\n",
      "  [-8.30566645e-01 -7.26322532e-01  1.42768133e+00  4.18363869e-01\n",
      "   -2.65647352e-01 -1.35616982e+00 -3.96123439e-01  1.68894458e+00\n",
      "   -1.63719308e+00  4.73582178e-01  4.98616368e-01  7.04834342e-01]\n",
      "  [-5.17160714e-01 -1.49072862e+00  1.17880642e+00  3.31496596e-01\n",
      "    7.09815547e-02 -1.38520610e+00 -9.42411125e-02  1.64038956e+00\n",
      "   -1.41560030e+00  3.04442942e-01  1.10239410e+00  2.74425387e-01]\n",
      "  [-1.08976769e+00 -1.36313009e+00  5.40457428e-01  1.25727105e+00\n",
      "    2.53534317e-02 -1.18918049e+00 -5.53741217e-01  1.83894980e+00\n",
      "   -1.01827407e+00  4.50826794e-01  8.07330728e-01  2.93904603e-01]\n",
      "  [-7.08027780e-01 -1.29848409e+00  7.81556368e-01  4.67977136e-01\n",
      "    8.09161603e-01 -1.27496099e+00 -3.95532578e-01  9.27892447e-01\n",
      "   -1.85646260e+00  6.30906641e-01  9.07397032e-01  1.00857711e+00]\n",
      "  [-6.34456158e-01 -9.60189164e-01  1.87708879e+00  8.65436375e-01\n",
      "   -8.44011307e-02 -1.21354842e+00 -7.69074500e-01  8.98617864e-01\n",
      "   -1.58086205e+00  5.67009032e-01  2.26811886e-01  8.07567120e-01]\n",
      "  [-1.86634168e-01 -1.54888618e+00  5.16934574e-01  4.49151933e-01\n",
      "    6.32246807e-02 -1.01804292e+00 -7.46566057e-03  1.76419508e+00\n",
      "   -1.89463580e+00  3.25392902e-01  9.52711523e-01  5.84053993e-01]\n",
      "  [-1.34244359e+00 -8.03303123e-01  1.16482377e+00  1.21057260e+00\n",
      "   -2.40505427e-01 -1.48181462e+00 -3.90893072e-01  1.42783213e+00\n",
      "   -9.42802668e-01  2.28745073e-01  1.05613321e-02  1.15922725e+00]\n",
      "  [-5.79813361e-01 -9.57023501e-01  1.47455418e+00  4.23895955e-01\n",
      "   -3.80938709e-01 -1.10984910e+00  2.33750641e-01  1.25877023e+00\n",
      "   -2.04217649e+00  6.60759509e-01  8.64403546e-01  1.53666779e-01]\n",
      "  [-9.93736684e-01 -1.24075532e+00  2.33183563e-01 -5.81370778e-02\n",
      "   -2.05542251e-01 -7.74608850e-01 -8.65995884e-01  2.31993771e+00\n",
      "   -5.37017107e-01  8.26615542e-02  1.38392615e+00  6.56083941e-01]]\n",
      "\n",
      " [[-1.24434125e+00 -1.15607321e+00  1.46786535e+00 -4.37565982e-01\n",
      "    9.41370606e-01 -1.19560993e+00 -5.56757689e-01  1.20041835e+00\n",
      "   -1.01356840e+00  8.31454754e-01  9.73613799e-01  1.89193577e-01]\n",
      "  [-1.15922928e+00 -4.80449259e-01  1.15429354e+00  4.14946437e-01\n",
      "   -2.83827603e-01 -1.14085841e+00 -9.79633451e-01  1.64137375e+00\n",
      "   -1.43781686e+00  8.61424446e-01  9.07077491e-01  5.02699494e-01]\n",
      "  [-8.97884965e-01 -1.20827138e+00  7.56534636e-01  7.11993396e-01\n",
      "   -3.42008531e-01  1.18590429e-01 -8.87051672e-02  1.31087935e+00\n",
      "   -2.04056644e+00 -8.21340829e-02  1.61395121e+00  1.47621423e-01]\n",
      "  [-6.25617683e-01 -8.52057457e-01  1.80935800e+00  3.20324779e-01\n",
      "   -7.02650666e-01 -1.09266448e+00 -5.84984899e-01  1.44724762e+00\n",
      "   -1.39987183e+00  9.38370287e-01  7.35945702e-01  6.60035759e-03]\n",
      "  [-2.16545790e-01 -1.74909973e+00  4.81527597e-01  6.86328650e-01\n",
      "   -1.04847953e-01 -8.63417685e-01  3.33910078e-01  1.74388599e+00\n",
      "   -1.73830545e+00  8.03761482e-01  7.69678831e-01 -1.46876350e-01]\n",
      "  [-1.63171291e+00 -5.28026044e-01  1.28913093e+00  1.08585632e+00\n",
      "   -4.22321558e-01 -1.33861363e+00 -5.04536211e-01  1.76866496e+00\n",
      "   -6.95130348e-01  1.58017218e-01  5.12990296e-01  3.05680931e-01]\n",
      "  [-8.82743061e-01 -8.97342741e-01  1.28131557e+00  8.52523148e-01\n",
      "    7.37708807e-03 -1.73471820e+00 -1.75876349e-01  1.78371036e+00\n",
      "   -1.17781842e+00  9.91951898e-02  6.11300886e-01  2.33076721e-01]\n",
      "  [-1.12561607e+00 -8.52567852e-02  1.25984693e+00  4.01770204e-01\n",
      "   -6.16109610e-01 -1.75190413e+00 -8.43227863e-01  2.13199782e+00\n",
      "    1.17379352e-01  2.55159199e-01  4.11019802e-01 -1.55058563e-01]\n",
      "  [-1.24282157e+00  1.14019215e-02  2.54881930e+00  6.44245148e-01\n",
      "   -1.32230580e-01 -1.77908850e+00 -5.34488797e-01  1.94820017e-01\n",
      "    4.85166907e-02  1.82584003e-01  3.40896025e-02  2.41524205e-02]\n",
      "  [-1.08176816e+00 -1.03714931e+00  1.35753417e+00  9.40800071e-01\n",
      "   -9.53862548e-01 -1.13664961e+00  5.24006113e-02  1.56031215e+00\n",
      "   -1.24903691e+00  6.46356165e-01  4.11074013e-01  4.89989609e-01]]], shape=(3, 10, 12), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "encoder_output, attention_weights = encoder(padded_input_seqs, training=True, mask = enc_mask)\n",
    "\n",
    "print(f\"Encoder output {encoder_output.shape}: \")\n",
    "print(encoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, hidden_dim, dropout_rate=0.1):\n",
    "    super(DecoderBlock, self).__init__()\n",
    "\n",
    "    self.mhsa1 = MultiHeadSelfAttention(d_model, num_heads)\n",
    "    self.mhsa2 = MultiHeadSelfAttention(d_model, num_heads)\n",
    "\n",
    "    self.ffn = feed_forward_network(d_model, hidden_dim)\n",
    "\n",
    "    self.dropout1 = tf.keras.layers.Dropout(dropout_rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(dropout_rate)\n",
    "    self.dropout3 = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization()\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization()\n",
    "    self.layernorm3 = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "  def call(self, encoder_output, target, training, decoder_mask, memory_mask):\n",
    "    mhsa_output1, attention_weights = self.mhsa1(target, target, target, decoder_mask)\n",
    "    mhsa_output1 = self.dropout1(mhsa_output1, training=training)\n",
    "    mhsa_output1 = self.layernorm1(mhsa_output1 + target)\n",
    "\n",
    "    mhsa_output2, attention_weights = self.mhsa2(mhsa_output1, encoder_output, \n",
    "                                            encoder_output, \n",
    "                                            memory_mask)\n",
    "    mhsa_output2 = self.dropout2(mhsa_output2, training=training)\n",
    "    mhsa_output2 = self.layernorm2(mhsa_output2 + mhsa_output1)\n",
    "\n",
    "    ffn_output = self.ffn(mhsa_output2)\n",
    "    ffn_output = self.dropout3(ffn_output, training=training)\n",
    "    output = self.layernorm3(ffn_output + mhsa_output2)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_blocks, d_model, num_heads, hidden_dim, target_vocab_size,\n",
    "               max_seq_len, dropout_rate=0.1):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.max_seq_len = max_seq_len\n",
    "\n",
    "    self.token_embed = tf.keras.layers.Embedding(target_vocab_size, self.d_model)\n",
    "    self.pos_embed = tf.keras.layers.Embedding(max_seq_len, self.d_model)\n",
    "\n",
    "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "    self.blocks = [DecoderBlock(self.d_model, num_heads, hidden_dim, dropout_rate) for _ in range(num_blocks)]\n",
    "\n",
    "  def call(self, encoder_output, target, training, decoder_mask, memory_mask):\n",
    "    token_embeds = self.token_embed(target)\n",
    "\n",
    "    num_pos = target.shape[0] * self.max_seq_len\n",
    "    pos_idx = np.resize(np.arange(self.max_seq_len), num_pos)\n",
    "    pos_idx = np.reshape(pos_idx, target.shape)\n",
    "\n",
    "    pos_embeds = self.pos_embed(pos_idx)\n",
    "\n",
    "    x = self.dropout(token_embeds + pos_embeds, training=training)\n",
    "\n",
    "    for block in self.blocks:\n",
    "      x, weights = block(encoder_output, x, training, decoder_mask, memory_mask)\n",
    "\n",
    "    return x, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_input_seqs = [\n",
    "    [1, 652, 723, 123, 62],\n",
    "    [1, 25,  98, 129, 248, 215, 359, 249],\n",
    "    [1, 2369, 1259, 125, 486],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded target inputs to the decoder:\n",
      "(3, 8)\n",
      "[[   1  652  723  123   62    0    0    0]\n",
      " [   1   25   98  129  248  215  359  249]\n",
      " [   1 2369 1259  125  486    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "padded_target_input_seqs = tf.keras.preprocessing.sequence.pad_sequences(target_input_seqs, padding=\"post\")\n",
    "print(\"Padded target inputs to the decoder:\")\n",
    "print(padded_target_input_seqs.shape)\n",
    "print(padded_target_input_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[1. 1. 1. 1. 1. 0. 0. 0.]]]\n",
      "\n",
      "\n",
      " [[[1. 1. 1. 1. 1. 1. 1. 1.]]]\n",
      "\n",
      "\n",
      " [[[1. 1. 1. 1. 1. 0. 0. 0.]]]], shape=(3, 1, 1, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "dec_padding_mask = tf.cast(tf.math.not_equal(padded_target_input_seqs, 0), tf.float32)\n",
    "dec_padding_mask = dec_padding_mask[:, tf.newaxis, tf.newaxis, :]\n",
    "print(dec_padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1.]], shape=(8, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "target_input_seq_len = padded_target_input_seqs.shape[1]\n",
    "look_ahead_mask = tf.linalg.band_part(tf.ones((target_input_seq_len, \n",
    "                                               target_input_seq_len)), -1, 0)\n",
    "print(look_ahead_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The decoder mask:\n",
      "tf.Tensor(\n",
      "[[[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "   [1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "   [1. 1. 1. 0. 0. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1. 0. 0. 0.]]]\n",
      "\n",
      "\n",
      " [[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "   [1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "   [1. 1. 1. 0. 0. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1. 1. 0. 0.]\n",
      "   [1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "   [1. 1. 1. 1. 1. 1. 1. 1.]]]\n",
      "\n",
      "\n",
      " [[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "   [1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "   [1. 1. 1. 0. 0. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "   [1. 1. 1. 1. 1. 0. 0. 0.]]]], shape=(3, 1, 8, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "dec_mask = tf.minimum(dec_padding_mask, look_ahead_mask)\n",
    "print(\"The decoder mask:\")\n",
    "print(dec_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-15 03:09:43.268316: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output (3, 8, 12):\n",
      "tf.Tensor(\n",
      "[[[-1.0734522  -1.079214    1.6303062   1.2163556  -0.78956246\n",
      "   -1.3172421  -0.15712343  0.12961079  0.80639815  0.4028942\n",
      "   -0.9555623   1.1865913 ]\n",
      "  [-1.0243477  -0.58710825  1.5379286   1.1225665  -0.6302651\n",
      "   -1.4034023  -0.15430467  0.32217252  1.0032556   0.31777847\n",
      "   -1.5251329   1.0208594 ]\n",
      "  [-0.82169926 -0.9687467   1.5137465   1.0379796  -0.5630022\n",
      "   -1.2522585   0.10352552  0.9428683   0.8983471   0.46200833\n",
      "   -1.7460334   0.39326474]\n",
      "  [-0.9825275  -0.57628626  1.6053392   0.5890902  -0.61369103\n",
      "   -1.2708597   0.06794469  0.52897346  0.90249616  0.4650961\n",
      "   -1.807985    1.0924097 ]\n",
      "  [-0.48202044 -0.51373583  0.8427286   1.4161934  -0.70780355\n",
      "   -0.98012197 -0.15206677 -0.2085001   1.2893338   0.4514563\n",
      "   -2.0474231   1.0919595 ]\n",
      "  [-0.9386519  -0.90609443  1.5460386   1.3454987  -0.55361265\n",
      "   -1.0964422   0.266388   -0.01726206  0.78934187  0.22665195\n",
      "   -1.6753157   1.0134602 ]\n",
      "  [-0.83064216 -0.6672186   1.0567138   1.6259869  -0.53129303\n",
      "   -1.2144443   0.10037838  0.2525064   1.054575    0.28647062\n",
      "   -1.8755946   0.7425619 ]\n",
      "  [-0.6598773  -0.77132714  1.3020514   1.2543746  -0.3627947\n",
      "   -1.1685274   0.27554518  0.17395927  1.0119437   0.3856583\n",
      "   -2.1128774   0.6718714 ]]\n",
      "\n",
      " [[-1.1836162   0.17957123  0.64388514  0.09771875 -0.45391083\n",
      "   -2.3133893   1.0221459   0.987739    0.97948545 -0.56855214\n",
      "   -0.43142915  1.0403521 ]\n",
      "  [-0.26369753 -0.19806223 -0.16385579  1.2284074  -0.19159581\n",
      "   -1.5072496   0.88261443 -0.0119744   1.2676828  -0.2890909\n",
      "   -2.001953    1.2487746 ]\n",
      "  [-0.55036896 -0.5234225   0.01301626  0.93117017 -0.42102194\n",
      "   -2.215816    0.38210094  0.6107703   1.546937    0.8727672\n",
      "   -1.2091733   0.5630406 ]\n",
      "  [-0.02491364  0.22173958  0.11207092  0.74978745 -0.73470145\n",
      "   -1.9271157  -0.3149197   0.12194705  1.5399238  -0.20816192\n",
      "   -1.263244    1.7275877 ]\n",
      "  [-0.44006756 -0.12037812  0.13607098  1.5038795  -0.6869775\n",
      "   -1.4265262   0.2603267  -0.10350399  1.1804614  -0.4129331\n",
      "   -1.5800304   1.6896782 ]\n",
      "  [-0.90690213 -0.21816063  0.198008    1.2528694  -0.1002922\n",
      "   -1.3947648   0.5033537   0.2567722   1.4072591  -0.28277594\n",
      "   -1.9261454   1.2107788 ]\n",
      "  [-0.6208355  -0.2849484   0.0928722   1.3927965  -0.40280026\n",
      "   -1.2787403   0.44923818  0.9351431   1.0575398  -0.37427536\n",
      "   -2.0605667   1.0945764 ]\n",
      "  [-0.66889703 -0.40446907  0.01189447  1.4095988  -0.9285023\n",
      "   -1.7346497   0.5332038   0.25193954  1.2854627  -0.44165677\n",
      "   -0.8989279   1.5850035 ]]\n",
      "\n",
      " [[-0.30818352 -0.63791496  0.6898791   1.7225394  -0.12302131\n",
      "   -1.065033    0.163687   -0.7753796   1.2660062  -0.14288189\n",
      "   -1.866918    1.0772204 ]\n",
      "  [-0.81073153 -0.93238026  0.89422965  0.84988356 -0.50704646\n",
      "   -1.6961026   0.35239315 -0.06007682  1.6844244   0.34928462\n",
      "   -1.2263018   1.102424  ]\n",
      "  [-0.5641146  -0.21766841  0.43962377  1.4541782  -0.28672895\n",
      "   -1.3703828   0.5565508  -0.34184974  1.4752998  -0.02425207\n",
      "   -1.9964771   0.8758211 ]\n",
      "  [-0.4536873   0.06572663  0.52541625  0.9993618   0.00499138\n",
      "   -1.5090238   0.43745008 -0.69028413  1.7050682   0.18329191\n",
      "   -2.0153286   0.7470174 ]\n",
      "  [-0.73550725 -0.14212874  0.24901608  1.2991556   0.30033076\n",
      "   -1.4710497   0.32237723 -0.33075568  1.2668358   0.07167327\n",
      "   -2.0364103   1.2064627 ]\n",
      "  [-0.5874629  -0.0553883  -0.11664282  0.6156005  -0.0590391\n",
      "   -1.4819044   0.71993846 -0.05706649  1.74407     0.21711875\n",
      "   -2.0505335   1.1113098 ]\n",
      "  [-0.5928344  -0.13892655 -0.01532802  0.9672077  -0.18448943\n",
      "   -1.0624864   0.7424389  -0.2930925   1.7577035   0.0403873\n",
      "   -2.199064    0.9784841 ]\n",
      "  [-0.6728027  -0.06095487 -0.07897694  1.3628252   0.13360672\n",
      "   -1.4055854   0.6895241  -0.5418553   1.4008738  -0.14717422\n",
      "   -1.8714006   1.19192   ]]], shape=(3, 8, 12), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(6, 12, 3, 48, 10000, 8)\n",
    "decoder_output, _ = decoder(encoder_output, padded_target_input_seqs, \n",
    "                            True, dec_mask, enc_mask)\n",
    "print(f\"Decoder output {decoder_output.shape}:\")\n",
    "print(decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "  def __init__(self, num_blocks, d_model, num_heads, hidden_dim, source_vocab_size,\n",
    "               target_vocab_size, max_input_len, max_target_len, dropout_rate=0.1):\n",
    "    super(Transformer, self).__init__()\n",
    "\n",
    "    self.encoder = Encoder(num_blocks, d_model, num_heads, hidden_dim, source_vocab_size, \n",
    "                           max_input_len, dropout_rate)\n",
    "    \n",
    "    self.decoder = Decoder(num_blocks, d_model, num_heads, hidden_dim, target_vocab_size,\n",
    "                           max_target_len, dropout_rate)\n",
    "    \n",
    "    # The final dense layer to generate logits from the decoder output.\n",
    "    self.output_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "  def call(self, input_seqs, target_input_seqs, training, encoder_mask,\n",
    "           decoder_mask, memory_mask):\n",
    "    encoder_output, encoder_attn_weights = self.encoder(input_seqs, \n",
    "                                                        training, encoder_mask)\n",
    "\n",
    "    decoder_output, decoder_attn_weights = self.decoder(encoder_output, \n",
    "                                                        target_input_seqs, training,\n",
    "                                                        decoder_mask, memory_mask)\n",
    "\n",
    "    return self.output_layer(decoder_output), encoder_attn_weights, decoder_attn_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer output (3, 8, 7000):\n",
      "tf.Tensor(\n",
      "[[[-0.05642275  0.02513913 -0.04338125 ...  0.01575807 -0.02423196\n",
      "   -0.04111049]\n",
      "  [-0.04408804  0.02414898 -0.10227228 ... -0.02808993  0.03069493\n",
      "   -0.06102085]\n",
      "  [-0.00465563  0.04543363 -0.09451631 ... -0.00123715 -0.05071724\n",
      "    0.03225553]\n",
      "  ...\n",
      "  [-0.05206156 -0.00774972 -0.03628813 ...  0.00924029  0.01225576\n",
      "   -0.04328141]\n",
      "  [-0.03390186  0.03991597 -0.06668885 ...  0.0190472  -0.04141977\n",
      "   -0.0387602 ]\n",
      "  [-0.05633464  0.01065958 -0.03857102 ...  0.01277313  0.01456492\n",
      "   -0.02440928]]\n",
      "\n",
      " [[ 0.01661561  0.02113944 -0.07620583 ... -0.03187927 -0.01650352\n",
      "   -0.01205103]\n",
      "  [ 0.00602331  0.00787767 -0.0331655  ...  0.00470732 -0.04223408\n",
      "   -0.01561172]\n",
      "  [-0.00793221 -0.00697175 -0.04534816 ...  0.01082534 -0.02547691\n",
      "   -0.00891706]\n",
      "  ...\n",
      "  [-0.03553086  0.00793064 -0.02056244 ...  0.00559565 -0.00507873\n",
      "   -0.03127439]\n",
      "  [-0.02636139 -0.01595749 -0.0172566  ...  0.01105426 -0.001003\n",
      "   -0.03645158]\n",
      "  [-0.01677059 -0.00612543 -0.04500499 ...  0.01548307  0.00058113\n",
      "   -0.00954089]]\n",
      "\n",
      " [[ 0.01583661  0.02881592 -0.09979407 ...  0.00682697 -0.04097989\n",
      "    0.00575635]\n",
      "  [-0.0488659   0.0271678  -0.06536522 ... -0.00396361 -0.01855244\n",
      "   -0.07390257]\n",
      "  [-0.02683963  0.01201231 -0.06763549 ...  0.00114785 -0.00107564\n",
      "   -0.02297454]\n",
      "  ...\n",
      "  [-0.0587985   0.01869357 -0.12007223 ... -0.01765926  0.01498603\n",
      "   -0.02500253]\n",
      "  [-0.03069097  0.01556929 -0.05686488 ...  0.00846401 -0.01925951\n",
      "   -0.07639637]\n",
      "  [-0.03448647  0.01663237 -0.05069917 ... -0.0133055   0.01920163\n",
      "   -0.04482258]]], shape=(3, 8, 7000), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "transformer = Transformer(\n",
    "    num_blocks = 6,\n",
    "    d_model = 12,\n",
    "    num_heads = 3,\n",
    "    hidden_dim = 48,\n",
    "    source_vocab_size = bpemb_vocab_size,\n",
    "    target_vocab_size = 7000, \n",
    "    max_input_len = padded_input_seqs.shape[1],\n",
    "    max_target_len = padded_target_input_seqs.shape[1])\n",
    "\n",
    "transformer_output, _, _ = transformer(padded_input_seqs, \n",
    "                                       padded_target_input_seqs, True, \n",
    "                                       enc_mask, dec_mask, memory_mask=enc_mask)\n",
    "print(f\"Transformer output {transformer_output.shape}:\")\n",
    "print(transformer_output) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
